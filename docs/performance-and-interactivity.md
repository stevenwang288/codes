# Performance & Interactivity（需求记录）

本文用于记录一次以“先评估、后落地”为原则的用户需求与现状定位，避免上下文被对话历史挤占，便于后续按优先级推进。

- 记录日期：2026-01-24
- 范围：Every Code（Code）CLI/TUI 交互、`apply_patch` 验证链路、构建耗时
- 关键约束：在用户确认前只做评估与信息收集，不做代码改动与长时构建

## 用户优先级（明确顺序）

用户给出的优先级为：

1. （优先级 2）`apply_patch` 执行后变慢（首要）
2. （优先级 3）编译/构建慢
3. （优先级 1）交互慢（用户发话时“插不进来”）
4. （优先级 4）更新/对比仓库体验

注：这里沿用用户原始编号与排序（“2 > 3 > 1 > 4”）。

## 症状 → 1-4 的映射（便于讨论时不跑题）

为了避免“大家各说各话”，建议每次反馈都先归到 1-4：

- (2) `apply_patch` 后慢：表现为“补丁应用完了但还要等很久才能继续”，常见原因是验证/扫描/外部工具或 git 操作。
- (3) 编译慢：表现为“构建时间长”，与冷缓存/依赖下载/并行度/平台 shell 相关。
- (1) 交互慢：表现为“运行中我说话插不进去/必须等它跑完”，更像队列语义与中断策略。
- (4) 更新/对比仓库：表现为“跟上游对比/更新不顺手”，偏工作流与命令入口设计。

你的当前描述（PowerShell、UI 可滚动、认为是机制问题）优先落在 (1)+(2)。

## 现状定位（代码指针）

以下指针用于后续评估时快速回到关键路径：

- `Ctrl+G`：当前实现是 Guide/Help overlay（不是命令中心/命令面板）
  - 入口：`code-rs/tui/src/chatwidget/help_handlers.rs`
  - 提示文案：`code-rs/tui/src/chatwidget.rs`

- 运行时输入/排队/中断（交互相关）：
  - `Op::Interrupt` / `Op::UserInput` / `Op::QueueUserInput`：`code-rs/core/src/codex/streaming.rs`

- `apply_patch` 验证/校验链路（性能相关）：
  - 调用入口：`code-rs/core/src/apply_patch.rs`
  - 验证 harness：`code-rs/core/src/patch_harness.rs`

## 社区线索（GitHub）

下面列出与本轮 1-4 相关的公开线索（用于后续深入阅读与对照实现）。

### (2) `apply_patch` 后慢 / 挂起

- 上游 `openai/codex`：
  - #7109「[WSL2] apply_patch hangs; Esc + two Ctrl+C required to exit session」（2025-12-07）
  - #7265「Everytime codex tries to use the `apply_patch` tool, it hangs indefinitely.」（2025-12-08）
  - #8161「Allow users to disable the built-in `apply_patch` tool (and interception)」（2025-12-17）

这些更偏向“工具/验证链路/平台差异（尤其 WSL/Windows）”而非纯模型推理耗时。

### (1) 交互慢 / 打断困难 / 排队语义

- `just-every/code`：
  - #440「Prompt queuing enhancements」（2025-12-08，Open）
- 上游 `openai/codex`：
  - #8604「Add message queuing」（2026-01-05，Open）
  - #4312「Allow Codex to ingest queued corrections while the current turn is still running」（2025-11-27，Open）

这些更偏向“产品语义与本地调度机制”的设计问题（中断/排队/并行），通常不是模型本身能单独解决。

### (3) 编译/构建慢

- `just-every/code`：
  - #485「Performance in long AutoDrive Sessions」（2026-01-04，Closed）
  - #419「…requires git repo presence to ./build-fast.sh」（2025-11-21，Closed）

注：构建慢常与冷缓存、平台 shell（Git Bash/WSL/PowerShell）、以及依赖下载/编译并行度相关。

### (4) UI 线程冻结（看起来像模型慢，但其实是本地阻塞）

- `just-every/code`：
  - #459「Blocking git operation in TaskStarted handler causes 25-30 second UI freeze」（2025-12-22，Closed）
  - #257「TUI hangs while creating ghost snapshot on large repositories」（2025-09-27，Closed）

这类问题的典型特征是“UI 彻底不响应”，通常应优先排查本地阻塞 IO（git/磁盘/索引）。

## 需求：为什么“我在交互，但你不理我”

用户反馈的核心不是“响应慢”，而是**不可抢占**：当助手正在执行（例如长输出、外部命令、验证链路）时，用户的输入无法及时被系统接收并影响当前执行。

从产品语义看，这里至少有 3 种期望：

1. **立刻打断当前运行**：用户一发话就停止当前 run，转而处理新输入。
2. **不打断，但明确可见地排队**：记录“你说的话我收到了”，并给出预计何时处理/如何手动中断。
3. **并行处理**：在不破坏当前 run 的前提下，开启另一条对话/任务并行（对 TUI 顺序、状态一致性、工具安全要求最高）。

## 问题归因：到底是模型、API、工具，还是 Code/Codex 机制？

这类“慢/卡/不理我”通常来自多个层叠层，建议用现象把问题先归类，再决定收集什么证据。

### 快速判别（与你当前描述对齐）

你给出的现象是：

- **PowerShell 环境**
- **UI 可以滚动**（说明没有典型 UI 线程“完全冻结”）
- 你认为是“项目自身运行机制”（Codex 分支的调度/交互语义问题），而不是 bug

这组信号更匹配：

- **(2) 工具/验证链路耗时**：例如 `apply_patch` 后进行验证、git 操作、扫描等，本质是本地工作。
- **(1) 交互语义偏排队**：运行中用户输入通常不会立即抢占当前 run，而是排队或等待显式 interrupt。

它不太像：

- **(4) UI 线程冻结**（因为你还能滚动/操作）。

### 1) 模型与 API（远端）

典型症状：

- UI 仍然能响应按键/滚动，但长时间看不到新 token。
- 同一请求在不同网络/账号/区域表现差异明显。

可能原因：

- 模型本身推理耗时（首 token 慢），或被限流/排队。
- 网络/代理导致连接抖动。

如何验证：

- 观察“从提交到首个 token”的时间是否稳定。
- 对比“同 prompt，禁用本地工具/验证”是否仍慢（若仍慢，更偏模型/API）。

### 2) Code/Codex 引擎机制（本地调度）

典型症状：

- 不是纯粹慢，而是“你输入了，但不会立刻影响当前 run”。
- 输入会被排队（例如 `QueueUserInput`），只有当前 run 结束后才处理。

可能原因：

- 默认语义偏“不中断继续跑”，需要显式 interrupt/halt 才抢占。
- 严格有序的 TUI 历史插入（order key）让并行/抢占变得更复杂。

如何验证：

- 查看是否走了排队路径（`Op::QueueUserInput`）以及是否触发 `notify_wait_interrupted`。

### 3) 工具与验证链路（本地执行）

典型症状：

- `apply_patch` 后出现明显停顿（尤其在大仓库/Windows/慢磁盘）。
- UI “在动/Thinking”，但实质在跑 git/验证工具/扫描。

可能原因：

- `apply_patch` 的 patch harness/验证命令耗时。
- 额外的 git 操作（如 ghost snapshot / 状态收集）导致阻塞。

如何验证：

- 记录 `apply_patch` 完成到“下一次可交互”的耗时。
- 看耗时是否与仓库规模/文件数量强相关（强相关更偏工具链）。

### 4) TUI/UI 线程阻塞（本地实现缺陷）

典型症状：

- UI 直接冻结：按键无响应、渲染不刷新，持续数秒到数十秒。

可能原因：

- 在 UI 热路径做了阻塞 IO（例如同步 git 操作）。

如何验证：

- 复现时观察是否“完全不能操作”；若是，这通常不是模型/API 问题。

## 可改造方向（先评估、后决策）

### 方案 A：新输入触发“软中断”（推荐先评估）

- 行为：检测到用户输入时，向运行中的引擎发送 interrupt；停止后再处理新输入。
- 优点：语义简单，用户体感最直接。
- 风险：
  - 中断点可能落在不理想的时机（例如刚要写入输出/刚启动子进程）。
  - 对工具执行（尤其不可撤销的外部命令）需要明确“中断能保证什么”。

### 方案 B：可见的输入排队 + 一键中断

- 行为：运行中允许输入，但不会立即执行；UI 显示“已收到输入（1 条）”；同时提供显式快捷键（如 Esc/Ctrl+C）中断。
- 优点：不会破坏当前执行，逻辑可控。
- 风险：用户仍然可能感知为“不理我”，除非 UI 反馈足够强。

### 方案 C：并行 run（高风险，高复杂）

- 行为：允许后台继续运行当前任务，同时把用户新输入作为新任务启动。
- 风险：
  - TUI 历史严格有序（每段流式输出必须绑定稳定 order key），并行会显著增加实现复杂度。
 - 共享工作区副作用（工具/补丁/文件写入）需要隔离或调度，否则会产生竞态。

## 可落地改造选项（从低风险到高风险）

### 选项 1：更强的“已收到输入”反馈（不改变语义）

- 目标：解决“你不理我”的主观感受，即使仍旧排队。
- 做法：运行中输入被 `QueueUserInput` 接收时，UI 明确展示“Queued (N)”并持续可见。
- 风险：基本无（只涉及 UI 提示）。

### 选项 2：新输入默认触发 interrupt（改变语义，但实现仍相对简单）

- 目标：用户输入=“停止当前 run，响应我”。
- 做法：提交用户消息时，若当前非 wait-only，则先 `Interrupt`，再走后续输入处理。
- 风险：中断点语义需要明确（对外部命令不可逆副作用要有提示）。

#### 本轮决定

- 用户选择：**B（新输入默认 interrupt 抢占当前 run）**
- 目标：解决“我在交互，但系统不立刻转而处理我”的机制问题。

## 需求：删除文件时移入 `bak/`（软删除）

### 目标

当 `apply_patch` 产生 `*** Delete File: <path>` 时，不直接物理删除；而是将目标文件移动到项目根目录下的 `bak/` 目录。

- 若 `bak/` 不存在：自动创建。
- 需要保留相对路径结构，避免同名冲突。

### 动机

- 降低误删风险，便于回滚与审计。
- 将“删除”变为可恢复操作，特别适用于模型/工具链自动修改场景。


### 选项 3：区分“工具运行中”与“模型流式中”的抢占策略

- 目标：更细粒度体验：比如模型在流式时可立即停，工具执行时提示“可取消但可能残留”。
- 风险：需要引入更多状态判定，但仍是单 run。

### 选项 4：真正并行 run（不建议作为第一步）

- 目标：彻底解决插话问题。
- 风险：与严格有序历史（order key）、工作区副作用隔离、工具调度冲突强相关。

## 评估输出格式（约定）

为避免“上下文耗尽但没有产出”，后续每一项评估至少包含：

- 触发条件（什么情况下会慢/会卡）
- 可观测指标（如何量化：时延、吞吐、冷/热缓存差异）
- 关键路径（代码指针 + 必要的事件/日志）
- 可选改造（分层：最小变更 / 中等变更 / 结构性变更）
- 风险与回滚策略
